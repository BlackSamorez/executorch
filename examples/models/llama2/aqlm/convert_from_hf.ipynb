{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "LOAD_PATH = \"/Users/blacksamorez/models/Llama-2-7b-AQLM-PV-2Bit-2x8-hf/model.safetensors\"\n",
    "SAVE_PATH = \"/Users/blacksamorez/models/Llama-2-7b-AQLM-PV-2Bit-2x8-hf/executorch.pth\"\n",
    "\n",
    "dict = load_file(LOAD_PATH)\n",
    "\n",
    "mapping = {\n",
    "    \"model.\": \"\",\n",
    "    \n",
    "    \"self_attn.q_proj\": \"attention.wq\",\n",
    "    \"self_attn.k_proj\": \"attention.wk\",\n",
    "    \"self_attn.v_proj\": \"attention.wv\",\n",
    "    \"self_attn.o_proj\": \"attention.wo\",\n",
    "    \n",
    "    \"mlp.up_proj\": \"feed_forward.w3\",\n",
    "    \"mlp.gate_proj\": \"feed_forward.w1\",\n",
    "    \"mlp.down_proj\": \"feed_forward.w2\",\n",
    "    \n",
    "    \"input_layernorm\": \"attention_norm\",\n",
    "    \"post_attention_layernorm\": \"ffn_norm\",\n",
    "    \n",
    "    \"lm_head\": \"output\",\n",
    "    \"embed_tokens\": \"tok_embeddings\",\n",
    "}\n",
    "\n",
    "\n",
    "new_dict = {}\n",
    "\n",
    "for key, value in dict.items():\n",
    "    for old, new in mapping.items():\n",
    "        key = key.replace(old, new)\n",
    "        \n",
    "    if \"attention.wq.codes\" in key or \"attention.wk.codes\" in key:\n",
    "        # [num_out_groups, num_in_groups, num_codebooks]\n",
    "        print(f\"Transposing codes {key} {value.shape=}\")\n",
    "        value = (value.reshape(32, 2, 128 // 2, -1, 2)\n",
    "            .transpose(1, 2)\n",
    "            .reshape(128 * 32, -1, 2))\n",
    "        \n",
    "    if \"attention.wq.scales\" in key or \"attention.wk.scales\" in key:\n",
    "        # [num_out_groups, 1, 1, 1]\n",
    "        print(f\"Transposing scales {key} {value.shape=}\")\n",
    "        value = (value.reshape(32, 2, 128 // 2, 1)\n",
    "            .transpose(1, 2)\n",
    "            .reshape(128 * 32, 1, 1, 1))\n",
    "    \n",
    "    new_dict[key] = value\n",
    "    \n",
    "del new_dict[\"output.weight\"]\n",
    "del new_dict[\"tok_embeddings.weight\"]\n",
    "\n",
    "torch.save(new_dict, SAVE_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
